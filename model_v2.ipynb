{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb33cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Activation,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e344ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_v2(size , learning_rate = 0.01 ):\n",
    "    \"\"\"Beginning of Model Architecture\"\"\"\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    # specify convolutional layer \n",
    "\n",
    "    # convolutional layer 1\n",
    "    model.add(Conv2D(filters = 32,kernel_size = (3,3),input_shape = (size[0],size[1],3) ,activation = 'relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # make a feature vector\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # dense layer\n",
    "\n",
    "    # hidden layer 1\n",
    "    model.add(Dense(10 , activation = 'relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation = 'sigmoid') )\n",
    "\n",
    "    \"\"\"End of Model architecture\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    optimizer\n",
    "    \"\"\"\n",
    "\n",
    "    # SGD \n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate  = learning_rate , momentum = 0.8)\n",
    "\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe15240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3443 images belonging to 2 classes.\n",
      "Found 737 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make generator for training and validation data\n",
    "\n",
    "size = (299,299)\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train/',\n",
    "    target_size = size,\n",
    "    batch_size = 64,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True \n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './val',\n",
    "    target_size = size,\n",
    "    batch_size = 64,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 320s 6s/step - loss: 0.6684 - accuracy: 0.5879 - val_loss: 0.6335 - val_accuracy: 0.6201\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 318s 6s/step - loss: 0.6085 - accuracy: 0.7037 - val_loss: 0.5824 - val_accuracy: 0.7571\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 299s 5s/step - loss: 0.5640 - accuracy: 0.7511 - val_loss: 0.5419 - val_accuracy: 0.7680\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 297s 5s/step - loss: 0.5287 - accuracy: 0.7787 - val_loss: 0.5073 - val_accuracy: 0.8019\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 298s 5s/step - loss: 0.4996 - accuracy: 0.8031 - val_loss: 0.4842 - val_accuracy: 0.8209\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 298s 5s/step - loss: 0.4665 - accuracy: 0.8310 - val_loss: 0.4518 - val_accuracy: 0.8318\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 296s 5s/step - loss: 0.4444 - accuracy: 0.8405 - val_loss: 0.4261 - val_accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 312s 6s/step - loss: 0.4151 - accuracy: 0.8641 - val_loss: 0.3988 - val_accuracy: 0.8779\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 303s 6s/step - loss: 0.3893 - accuracy: 0.8832 - val_loss: 0.3755 - val_accuracy: 0.8874\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 298s 5s/step - loss: 0.3700 - accuracy: 0.8879 - val_loss: 0.3589 - val_accuracy: 0.8915\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 304s 6s/step - loss: 0.6787 - accuracy: 0.5614 - val_loss: 0.6760 - val_accuracy: 0.5631\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 298s 5s/step - loss: 0.6611 - accuracy: 0.5722 - val_loss: 0.6504 - val_accuracy: 0.5712\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 298s 5s/step - loss: 0.6313 - accuracy: 0.6375 - val_loss: 0.6124 - val_accuracy: 0.6784\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 295s 5s/step - loss: 0.5948 - accuracy: 0.6982 - val_loss: 0.5812 - val_accuracy: 0.8005\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 294s 5s/step - loss: 0.5466 - accuracy: 0.7508 - val_loss: 0.5240 - val_accuracy: 0.6811\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 296s 5s/step - loss: 0.4988 - accuracy: 0.7961 - val_loss: 0.4619 - val_accuracy: 0.7992\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 346s 6s/step - loss: 0.4023 - accuracy: 0.8716 - val_loss: 0.2968 - val_accuracy: 0.9308\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 312s 6s/step - loss: 0.2913 - accuracy: 0.8998 - val_loss: 0.2343 - val_accuracy: 0.9159\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 302s 6s/step - loss: 0.2024 - accuracy: 0.9422 - val_loss: 0.1753 - val_accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 297s 5s/step - loss: 0.2250 - accuracy: 0.9082 - val_loss: 0.1823 - val_accuracy: 0.9159\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 310s 6s/step - loss: 0.6955 - accuracy: 0.5588 - val_loss: 0.6873 - val_accuracy: 0.5631\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 324s 6s/step - loss: 0.6864 - accuracy: 0.5629 - val_loss: 0.6857 - val_accuracy: 0.5631\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 318s 6s/step - loss: 0.6856 - accuracy: 0.5629 - val_loss: 0.6853 - val_accuracy: 0.5631\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 269s 5s/step - loss: 0.6854 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 235s 4s/step - loss: 0.6853 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 242s 4s/step - loss: 0.6854 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 234s 4s/step - loss: 0.6853 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 216s 4s/step - loss: 0.6853 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 199s 4s/step - loss: 0.6853 - accuracy: 0.5629 - val_loss: 0.6852 - val_accuracy: 0.5631\n",
      "Epoch 10/10\n",
      "27/54 [==============>...............] - ETA: 1:17 - loss: 0.6897 - accuracy: 0.5446"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "os.mkdir( os.path.join(os.getcwd(),'checkpoint','model_v2') )\n",
    "\n",
    "for lr in [0.0001 , 0.001 , 0.01 , 0.1]:\n",
    "    \n",
    "    # define checkpoint for every learning rate\n",
    "    filename = 'model_v2_{epoch:02d}_{val_accuracy:.3f}.h5'\n",
    "    \n",
    "    os.mkdir( os.path.join(os.getcwd(),'checkpoint','model_v2',f'lr={lr}') )\n",
    "    filepath = os.path.join(os.getcwd(),'checkpoint','model_v2',f'lr={lr}',filename)\n",
    "\n",
    "    checkpoint =keras.callbacks.ModelCheckpoint(\n",
    "    filepath ,\n",
    "    save_best_only=False,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max' ,\n",
    "    save_freq = 'epoch'\n",
    ")\n",
    "    \n",
    "    model=make_model_v2(size=size,learning_rate = lr)\n",
    "    history = model.fit(train_ds,epochs=10,validation_data=val_ds,callbacks = [checkpoint])\n",
    "    scores[lr] = history.history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fa2f4",
   "metadata": {},
   "source": [
    "I am not sure about this result , seems i do some mistake . So i stop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079169e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
